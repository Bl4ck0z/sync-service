# Proyecto: Sistema de SincronizaciÃ³n SQL Server â†’ PostgreSQL con Redis

**Autor:** Joel Santana H.  
**Fecha inicio:** 15/7/2025  
**Empresa:** Facu Importaciones  
**PropÃ³sito:** SincronizaciÃ³n de datos de conduces y planificaciÃ³n para usuarios en NocoDB

---

## ðŸ“‹ DescripciÃ³n del Proyecto

Sistema de sincronizaciÃ³n en tiempo real que transfiere datos desde SQL Server 2016 hacia PostgreSQL, utilizando Redis como cola intermedia para maximizar rendimiento y confiabilidad.

### ðŸŽ¯ Objetivo Principal
- Sincronizar vista `VW_VENTAS_SYNC` desde SQL Server a PostgreSQL
- Permitir a usuarios editar campos de planificaciÃ³n en NocoDB
- Separar datos de solo lectura (SQL Server) de datos editables (usuarios)

### ðŸ—ï¸ Arquitectura Implementada
```
SQL Server 2016 â†’ Redis Queue â†’ PostgreSQL â†’ NocoDB
     â†“              â†“              â†“          â†“
VW_VENTAS_SYNC  change_queue  datos_vista  Interface
                               datos_seguimiento  Usuarios
```

---

## ðŸš€ Progreso Actual

### âœ… Pasos Completados

#### **Paso 1: Estructura bÃ¡sica** âœ…
- Script Python con imports bÃ¡sicos
- Estructura de funciones
- DocumentaciÃ³n y comentarios

#### **Paso 2: Sistema de logging** âœ…
- ConfiguraciÃ³n de logging a archivo y consola
- Niveles INFO, WARNING, ERROR
- Formato con timestamp y nivel

#### **Paso 3: Variables de entorno** âœ…
- Carga de archivo `.env` 
- ValidaciÃ³n de variables requeridas
- ConfiguraciÃ³n SQL Server, PostgreSQL, Redis
- FunciÃ³n `load_env_file()` para compatibilidad local/Docker

#### **Paso 4: Conexiones a bases de datos** âœ…
- Prueba de conexiÃ³n a SQL Server (pymssql)
- Prueba de conexiÃ³n a PostgreSQL (psycopg2)
- Prueba de conexiÃ³n a Redis (redis-py)
- ValidaciÃ³n completa antes de iniciar sync

#### **Paso 4.5: Base de datos PostgreSQL** âœ…
- Base de datos `syncdb` creada
- Tabla `datos_vista` (solo lectura - datos SQL Server)
- Tabla `datos_trabajo` (CRUD usuarios - campos editables)
- Foreign key entre tablas por `conduce`
- Triggers para `updated_at` automÃ¡tico
- Ãndices para rendimiento

### ðŸ”„ Paso Actual: **Paso 5 - LÃ³gica de sincronizaciÃ³n**

**Estado:** En desarrollo  
**Progreso:** 70% - Arquitectura definida, pendiente implementaciÃ³n Producer-Consumer

---

## ðŸ“Š Arquitectura TÃ©cnica

### ðŸ—„ï¸ Bases de Datos

#### **SQL Server 2016** (Origen)
- **Host:** 10.0.0.6:1433
- **Base de datos:** g_FACU
- **Usuario:** INV (permisos de solo lectura)
- **Vista:** `VW_VENTAS_SYNC`
- **Campos clave:** `CONDUCE`, `ULTIMA_MODIFICACION`, `FACTURADO`

#### **PostgreSQL** (Destino)
- **Host:** 127.0.0.1:5432 (local) / postgres (Docker)
- **Base de datos:** syncdb
- **Usuario:** sysadmin

**Tablas:**
```sql
-- Datos sincronizados (solo lectura)
datos_vista (
    sync_id, conduce PRIMARY KEY, fecha_emision, 
    facturado, numero_factura, codigo_cliente, 
    cliente, ultima_modificacion, created_at, updated_at
)

-- Datos editables usuarios  
datos_seguimiento (
    id SERIAL PRIMARY KEY, conduce UNIQUE,
    nota, ruta, trabajado, preparador,
    created_at, updated_at,
    FOREIGN KEY (conduce) REFERENCES datos_vista(conduce)
)
```

#### **Redis** (Cola intermedia)
- **Host:** 127.0.0.1:6379
- **Password:** Propose1-Amused-Cotton
- **Estructuras:**
  - `change_queue`: Cola FIFO para registros a sincronizar
  - `last_sync_timestamp`: Ãšltimo timestamp procesado
  - `client_cache`: Cache para datos frecuentes (futuro)

### ðŸ”„ Flujo de Datos

#### **Producer Process**
1. Lee `last_sync_timestamp` desde Redis
2. Query incremental: `WHERE ULTIMA_MODIFICACION > last_sync`
3. Por cada registro: `LPUSH change_queue JSON(record)`
4. Actualiza `last_sync_timestamp` en Redis
5. Repeat cada 10 segundos

#### **Consumer Process**
1. `BRPOP change_queue` (bloqueo hasta datos)
2. Procesa batch de registros
3. UPSERT en `datos_vista`: `INSERT ON CONFLICT DO UPDATE`
4. Confirma procesamiento
5. Repeat continuamente

---

## âš™ï¸ ConfiguraciÃ³n

### ðŸ“ Variables de Entorno (.env)
```bash
# SQL Server 2016
MSSQL_HOST=10.0.0.6
MSSQL_PORT=1433
MSSQL_DATABASE=g_FACU
MSSQL_USER=INV
MSSQL_PASSWORD=F4cu@db01
MSSQL_VIEW=VW_VENTAS_SYNC

# PostgreSQL (contenedor separado)
PG_HOST=127.0.0.1           # local testing
PG_PORT=5432
PG_DATABASE=syncdb
PG_USER=sysadmin
PG_PASSWORD=Tux-Plural-Retype3
PG_TABLE_VISTA=datos_vista
PG_TABLE_SEGUIMIENTO=datos_seguimiento

# Redis (contenedor separado)
REDIS_HOST=127.0.0.1          # Docker container name
REDIS_PORT=6379
REDIS_PASSWORD=Propose1-Amused-Cotton
REDIS_DB=0

# Sync Settings
SYNC_INTERVAL=60            # Producer frequency (seconds)
BATCH_SIZE=50               # Consumer batch size
```

### ðŸ³ **ConfiguraciÃ³n Multi-Contenedor**
- **Redis**: Contenedor separado `redis` 
- **PostgreSQL**: Contenedor separado `postgres`
- **Sync Service**: Nuevo contenedor que se conecta a ambos

### ðŸ“¦ Dependencias Python
```txt
pymssql==2.2.11      # SQL Server connector
psycopg2-binary      # PostgreSQL connector  
redis==4.5.4         # Redis client
python-dateutil      # Date parsing (mejor compatibilidad)
```

**InstalaciÃ³n:**
```bash
# OpciÃ³n 1: apt (recomendado para Ubuntu)
sudo apt install python3-pymssql python3-psycopg2 python3-redis python3-dateutil

# OpciÃ³n 2: pip (si no funciona apt)
pip3 install pymssql psycopg2-binary redis python-dateutil
```

---

## ðŸ“ Estructura de Archivos

```
/home/sysadmin/docker/sync-service/
â”œâ”€â”€ sync_script.py          # Script principal (en desarrollo)
â”œâ”€â”€ .env                    # Variables de entorno
â”œâ”€â”€ requirements.txt        # Dependencias Python (futuro)
â”œâ”€â”€ Dockerfile             # Imagen Docker (futuro)
â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n (futuro)
â”œâ”€â”€ entrypoint.sh          # Script inicio (futuro)
â””â”€â”€ logs/
    â””â”€â”€ sync.log           # Logs de ejecuciÃ³n
```

### ðŸ—„ï¸ PostgreSQL
```
/scripts/create_syncdb.sql  # Script creaciÃ³n base de datos
```

---

## ðŸŽ¯ PrÃ³ximos Pasos

### **Paso 5: Implementar Producer-Consumer** (En progreso)

#### **5.1 Producer Process** ðŸŸ¨
- [ ] FunciÃ³n `producer_process(config, logger)`
- [ ] Loop cada 10 segundos
- [ ] Query incremental SQL Server
- [ ] Push a Redis queue
- [ ] Actualizar timestamp

#### **5.2 Consumer Process** ðŸŸ¨  
- [ ] FunciÃ³n `consumer_process(config, logger)`
- [ ] BRPOP desde Redis queue
- [ ] Batch processing
- [ ] UPSERT PostgreSQL
- [ ] Confirmar procesado

#### **5.3 Threading y Control** ðŸŸ¨
- [ ] Threads separados para Producer/Consumer
- [ ] Graceful shutdown (Ctrl+C)
- [ ] Manejo de errores robusto
- [ ] Health checks

### **Paso 6: Loop principal y timing** â¸ï¸
- [ ] CoordinaciÃ³n entre procesos
- [ ] MÃ©tricas de rendimiento
- [ ] Logging avanzado

### **Paso 7: ContainerizaciÃ³n** â¸ï¸
- [ ] requirements.txt
- [ ] Dockerfile optimizado
- [ ] docker-compose.yml con Redis
- [ ] entrypoint.sh

### **Paso 8: Testing y deployment** â¸ï¸
- [ ] Pruebas de carga
- [ ] ValidaciÃ³n de datos
- [ ] Monitoreo y alertas
- [ ] DocumentaciÃ³n final

### **Paso 9: NocoDB Integration** â¸ï¸
- [ ] ConexiÃ³n a PostgreSQL
- [ ] ConfiguraciÃ³n de tablas
- [ ] Permisos de usuario
- [ ] Interface final

---

## ðŸ”§ Comandos Ãštiles

### **Desarrollo Local**
```bash
# Ejecutar script
cd /home/sysadmin/docker/sync-service/
python3 sync_script.py

# Ver logs
tail -f logs/sync.log

# Monitorear Redis
redis-cli -h 127.0.0.1 -p 6379 -a "Propose1-Amused-Cotton"
> LLEN change_queue
> GET last_sync_timestamp
```

### **PostgreSQL**
```bash
# Conectar a syncdb
psql -h 127.0.0.1 -U sysadmin -d syncdb

# Ver tablas
\dt

# Contar registros
SELECT COUNT(*) FROM datos_vista;
SELECT COUNT(*) FROM datos_trabajo;
```

---

## ðŸ“ˆ MÃ©tricas de Rendimiento Esperadas

### **Rendimiento objetivo:**
- **Latencia:** < 30 segundos para cambios nuevos
- **Throughput:** 1000+ registros/minuto
- **Disponibilidad:** 99.9%
- **Error rate:** < 0.1%

### **Optimizaciones implementadas:**
- âœ… **Consultas incrementales** (timestamp-based)
- âœ… **UPSERT** en lugar de SELECT + INSERT/UPDATE
- âœ… **Batch processing** para transacciones
- âœ… **Redis queue** para desacoplamiento
- âœ… **Ãndices** en campos consultados frecuentemente

---

## ðŸš¨ Problemas Conocidos y Soluciones

### **1. ConexiÃ³n SQL Server**
**Problema:** Error de conexiÃ³n a 10.0.0.6  
**SoluciÃ³n:** Verificar red, firewall, y credenciales usuario INV

### **2. PostgreSQL local vs Docker**
**Problema:** Host diferente segÃºn entorno  
**SoluciÃ³n:** Variable PG_HOST en .env (127.0.0.1 local, postgres Docker)

### **3. Redis password**
**Problema:** AutenticaciÃ³n Redis  
**SoluciÃ³n:** Variable REDIS_PASSWORD configurada correctamente

### **4. Timestamp sync**
**Problema:** Primer sync trae todos los datos  
**SoluciÃ³n:** Implementado fallback a 2000-01-01 para primera ejecuciÃ³n

---

## ðŸŽ¯ Decisiones de DiseÃ±o Importantes

### **1. Â¿Por quÃ© Redis Queue?**
- **Desacoplamiento:** Producer y Consumer independientes
- **Rendimiento:** Memoria > Disco para cola
- **Confiabilidad:** Persistencia y retry automÃ¡tico
- **Escalabilidad:** FÃ¡cil agregar mÃºltiples consumers

### **2. Â¿Por quÃ© dos tablas separadas?**
- **datos_vista:** Solo lectura, datos "puros" de SQL Server
- **datos_trabajo:** CRUD usuarios, campos editables
- **Integridad:** Foreign key garantiza consistencia
- **Seguridad:** Permisos granulares por tabla

### **3. Â¿Por quÃ© UPSERT?**
- **Eficiencia:** Una query vs SELECT + INSERT/UPDATE
- **Atomicidad:** OperaciÃ³n transaccional
- **Simplicidad:** Menos cÃ³digo, menos errores

### **4. Â¿Por quÃ© timestamp en Redis?**
- **Velocidad:** Redis >> PostgreSQL para operaciones simples
- **Disponibilidad:** Acceso rÃ¡pido para Producer
- **Backup:** Tabla sync_control como fallback

---

## ðŸ“ž Contacto y Notas

**Desarrollador:** Joel Santana H.  
**Empresa:** Facu Importaciones  
**UbicaciÃ³n:** Santo Domingo Este, RD

**Notas importantes:**
- Proyecto enfocado en **rendimiento y confiabilidad**
- **Sin dashboard** - solo funcionalidad core
- Trabajo por **pasos incrementales**
- DocumentaciÃ³n **paso a paso** para facilitar debugging

---

*Ãšltimo update: 16/7/2025 - Paso 5 en progreso*